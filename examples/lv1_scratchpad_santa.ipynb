{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8504f01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from flax import struct\n",
    "import chex\n",
    "from typing import Any, Type, TypeVar, Generic, ClassVar, Union, Iterator, List, Optional, Tuple\n",
    "\n",
    "# --- Types & Constants ---\n",
    "G = TypeVar(\"G\", bound=\"BaseGenome\")\n",
    "\n",
    "class DistanceMetric:\n",
    "    HAMMING = \"hamming\"\n",
    "    EUCLIDEAN = \"euclidean\"\n",
    "    MANHATTAN = \"manhattan\"\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "@struct.dataclass\n",
    "class LinearGenomeConfig:\n",
    "    length: int           # L: Number of instructions\n",
    "    num_inputs: int       # N: Number of input features\n",
    "    num_ops: int          # Number of available functions\n",
    "    max_arity: int = 2    # Arguments per instruction\n",
    "\n",
    "# ==========================================\n",
    "# 2. BASE GENOME (Abstract Individual)\n",
    "# ==========================================\n",
    "@struct.dataclass\n",
    "class BaseGenome:\n",
    "    \"\"\"\n",
    "    Abstract base class for a Single Individual.\n",
    "    \"\"\"\n",
    "    # --- Abstract Interface ---\n",
    "    @classmethod\n",
    "    def random_init(cls: Type[G], key: chex.PRNGKey, config: Any) -> G:\n",
    "        \"\"\"Create ONE random genome.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def distance(self, other: \"BaseGenome\", metric: str) -> float:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def autocorrect(self, config: Any) -> \"BaseGenome\":\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @property\n",
    "    def size(self) -> int:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # --- Shared Logic (Vectorization) ---\n",
    "    @classmethod\n",
    "    def create_population(cls: Type[G], key: chex.PRNGKey, config: Any, pop_size: int) -> G:\n",
    "        \"\"\"\n",
    "        Vectorizes random_init to create a raw batch of genomes.\n",
    "        Returns object with shape (Pop, ...).\n",
    "        \"\"\"\n",
    "        keys = jax.random.split(key, pop_size)\n",
    "        return jax.vmap(cls.random_init, in_axes=(0, None))(keys, config)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 4. BASE POPULATION (Abstract Container)\n",
    "# ==========================================\n",
    "@struct.dataclass\n",
    "class BasePopulation(Generic[G]):\n",
    "    \"\"\"\n",
    "    Abstract Container. \n",
    "    Implements List-like behavior and automated Vectorization.\n",
    "    \"\"\"\n",
    "    genes: G\n",
    "    fitness: chex.Array\n",
    "    \n",
    "    GENOME_CLS: ClassVar[Type[G]]\n",
    "\n",
    "    # --- The \"Kebab\" Interface (List Behavior) ---\n",
    "    def __len__(self) -> int:\n",
    "        return int(self.fitness.shape[0])\n",
    "\n",
    "    def __getitem__(self, key: Union[int, slice, chex.Array]) -> Union[G, \"BasePopulation[G]\"]:\n",
    "        # Slice the genes Pytree automatically\n",
    "        sliced_genes = jax.tree_util.tree_map(lambda x: x[key], self.genes)\n",
    "        \n",
    "        if isinstance(key, int):\n",
    "            # Return Single Genome\n",
    "            return sliced_genes\n",
    "        else:\n",
    "            # Return Sliced Population\n",
    "            return self.replace(genes=sliced_genes, fitness=self.fitness[key])\n",
    "\n",
    "    def __iter__(self) -> Iterator[G]:\n",
    "        for i in range(len(self)):\n",
    "            yield self[i]\n",
    "\n",
    "    # --- Automated Logic (Vectorized) ---\n",
    "    def autocorrect(self, config: Any) -> \"BasePopulation[G]\":\n",
    "        \"\"\"Autocorrects entire batch.\"\"\"\n",
    "        new_genes = jax.vmap(lambda g: g.autocorrect(config))(self.genes)\n",
    "        return self.replace(genes=new_genes)\n",
    "\n",
    "    def distance_matrix(self, metric: str = \"hamming\") -> chex.Array:\n",
    "        \"\"\"Computes N x N distance matrix.\"\"\"\n",
    "        pair_fn = lambda g1, g2: g1.distance(g2, metric)\n",
    "        return jax.vmap(jax.vmap(pair_fn, in_axes=(None, 0)), in_axes=(0, None))(self.genes, self.genes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ed2c772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import struct\n",
    "import chex\n",
    "from functools import partial\n",
    "from typing import Any, Tuple, Callable, TypeVar, Generic\n",
    "\n",
    "# --- B. The Abstract Evaluator ---\n",
    "G = TypeVar(\"G\", bound=\"BaseGenome\")\n",
    "C = TypeVar(\"C\") # Config Type\n",
    "D = TypeVar(\"D\") # Data Type\n",
    "\n",
    "@struct.dataclass\n",
    "class BaseEvaluator(Generic[G, C, D]):\n",
    "    config: C\n",
    "\n",
    "    def evaluate(self, genome: G, data: D) -> float:\n",
    "        \"\"\"Abstract: Returns scalar fitness for one genome.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def evaluate_population(self, population: \"BasePopulation[G]\", data: D) -> \"BasePopulation[G]\":\n",
    "        \"\"\"Auto-Vectorization: Pop x Data -> Pop (with Fitness)\"\"\"\n",
    "        # vmap over genes (axis 0), keep self/data constant\n",
    "        fitness_scores = jax.vmap(self.evaluate, in_axes=(0, None))(population.genes, data)\n",
    "        return population.replace(fitness=fitness_scores)\n",
    "\n",
    "# --- C. The Concrete Linear Evaluator ---\n",
    "# Data Type: Tuple(Inputs, Targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33207d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import struct\n",
    "import chex\n",
    "from typing import Any, TypeVar, Generic\n",
    "\n",
    "# Generic Types\n",
    "G = TypeVar(\"G\", bound=\"BaseGenome\")\n",
    "C = TypeVar(\"C\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. ABSTRACT BASE: MUTATION\n",
    "# ==========================================\n",
    "@struct.dataclass\n",
    "class BaseMutation(Generic[G, C]):\n",
    "    \"\"\"\n",
    "    Abstract Mutation Functor.\n",
    "    \"\"\"\n",
    "    # --- STATIC PARAMS (Re-compile if changed) ---\n",
    "    # Determines the output shape: (N_Offspring, ...)\n",
    "    num_offspring: int = struct.field(pytree_node=False, default=1)\n",
    "\n",
    "    def __call__(self, key: chex.PRNGKey, genome: G, config: C) -> G:\n",
    "        \"\"\"\n",
    "        Applies mutation to produce 'num_offspring' children.\n",
    "        Output Shape: (Num_Offspring, Genome_Size...)\n",
    "        \"\"\"\n",
    "        # 1. Split keys for the static number of children\n",
    "        keys = jax.random.split(key, self.num_offspring)\n",
    "        \n",
    "        # 2. Vectorize the single mutation logic\n",
    "        # vmap over keys (axis 0), keep genome & config constant\n",
    "        return jax.vmap(\n",
    "            lambda k, g, c: self._mutate_one(k, g, c), \n",
    "            in_axes=(0, None, None)\n",
    "        )(keys, genome, config)\n",
    "\n",
    "    def _mutate_one(self, key: chex.PRNGKey, genome: G, config: C) -> G:\n",
    "        \"\"\"Abstract: Logic to produce EXACTLY ONE mutant.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 2. ABSTRACT BASE: CROSSOVER\n",
    "# ==========================================\n",
    "@struct.dataclass\n",
    "class BaseCrossover(Generic[G, C]):\n",
    "    \"\"\"\n",
    "    Abstract Crossover Functor.\n",
    "    \"\"\"\n",
    "    # --- STATIC PARAMS (Re-compile if changed) ---\n",
    "    num_offspring: int = struct.field(pytree_node=False, default=1)\n",
    "\n",
    "    def __call__(self, key: chex.PRNGKey, p1: G, p2: G, config: C) -> G:\n",
    "        \"\"\"\n",
    "        Combines two parents to produce 'num_offspring' children.\n",
    "        Output Shape: (Num_Offspring, Genome_Size...)\n",
    "        \"\"\"\n",
    "        keys = jax.random.split(key, self.num_offspring)\n",
    "        \n",
    "        # vmap over keys (axis 0), keep parents & config constant\n",
    "        return jax.vmap(\n",
    "            lambda k, a, b, c: self._cross_one(k, a, b, c),\n",
    "            in_axes=(0, None, None, None)\n",
    "        )(keys, p1, p2, config)\n",
    "\n",
    "    def _cross_one(self, key: chex.PRNGKey, p1: G, p2: G, config: C) -> G:\n",
    "        \"\"\"Abstract: Logic to produce EXACTLY ONE child.\"\"\"\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e156154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import struct\n",
    "import chex\n",
    "from typing import Generic\n",
    "\n",
    "# Generic Genome Type not needed here, strictly math!\n",
    "\n",
    "@struct.dataclass\n",
    "class BaseSelection:\n",
    "    \"\"\"\n",
    "    Abstract Selection Operator.\n",
    "    Operates purely on Fitness Arrays to return Indices.\n",
    "    \"\"\"\n",
    "    # STATIC: How many parents do we want to pick?\n",
    "    num_selections: int = struct.field(pytree_node=False)\n",
    "\n",
    "    def __call__(self, key: chex.PRNGKey, fitness: chex.Array) -> chex.Array:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            key: RNG Key\n",
    "            fitness: Shape (Pop_Size, ...) - Can be 1D or 2D (Symbiotic)\n",
    "            \n",
    "        Returns:\n",
    "            Selected Indices: Shape (num_selections,) int32\n",
    "        \"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41337e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import struct\n",
    "import chex\n",
    "from typing import Any, Tuple\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "@struct.dataclass\n",
    "class SantaConfig:\n",
    "    num_trees: int        # N\n",
    "    min_pos: float = -100.0\n",
    "    max_pos: float = 100.0\n",
    "    \n",
    "    # Precision scaling (optional, but good for stability)\n",
    "    scale_factor: float = 1.0 \n",
    "\n",
    "# --- THE CONTINUOUS GENOME ---\n",
    "@struct.dataclass\n",
    "class ContinuousGenome(BaseGenome):\n",
    "    # Shape: (Num_Trees, 3) -> [x, y, theta]\n",
    "    values: chex.Array  \n",
    "\n",
    "    @classmethod\n",
    "    def random_init(cls, key: chex.PRNGKey, config: SantaConfig) -> \"ContinuousGenome\":\n",
    "        k1, k2 = jax.random.split(key)\n",
    "        \n",
    "        # 1. Generate X, Y in [-100, 100]\n",
    "        pos = jax.random.uniform(\n",
    "            k1, shape=(config.num_trees, 2), \n",
    "            minval=config.min_pos, maxval=config.max_pos\n",
    "        )\n",
    "        \n",
    "        # 2. Generate Angle in [0, 360)\n",
    "        deg = jax.random.uniform(\n",
    "            k2, shape=(config.num_trees, 1), \n",
    "            minval=0.0, maxval=360.0\n",
    "        )\n",
    "        \n",
    "        # 3. Combine\n",
    "        values = jnp.concatenate([pos, deg], axis=1)\n",
    "        return cls(values=values)\n",
    "\n",
    "    def autocorrect(self, config: SantaConfig) -> \"ContinuousGenome\":\n",
    "        \"\"\"\n",
    "        Enforces constraints:\n",
    "        1. X, Y must be inside bounding box.\n",
    "        2. Degrees must be wrapped modulo 360 (Periodic).\n",
    "        \"\"\"\n",
    "        x = self.values[:, 0]\n",
    "        y = self.values[:, 1]\n",
    "        deg = self.values[:, 2]\n",
    "        \n",
    "        # Clip Position\n",
    "        x = jnp.clip(x, config.min_pos, config.max_pos)\n",
    "        y = jnp.clip(y, config.min_pos, config.max_pos)\n",
    "        \n",
    "        # Wrap Angle (0 to 360)\n",
    "        deg = deg % 360.0\n",
    "        \n",
    "        # Reconstruct\n",
    "        new_values = jnp.stack([x, y, deg], axis=1)\n",
    "        return self.replace(values=new_values)\n",
    "\n",
    "    def distance(self, other: \"ContinuousGenome\", metric: str = \"euclidean\") -> float:\n",
    "        \"\"\"Euclidean distance in the 3D configuration space.\"\"\"\n",
    "        diff = self.values - other.values\n",
    "        # Note: Angle distance should technically be circular (min(|a-b|, 360-|a-b|))\n",
    "        # But simple Euclidean is fine for a rough diversity metric.\n",
    "        return jnp.linalg.norm(diff)\n",
    "\n",
    "    @property\n",
    "    def size(self) -> int:\n",
    "        return self.values.shape[0]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<SantaGenome(N={self.values.shape[0]}, device={self.values.device})>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9593da9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@struct.dataclass\n",
    "class GaussianMutation(BaseMutation[ContinuousGenome, SantaConfig]):\n",
    "    # STATIC\n",
    "    num_offspring: int = struct.field(pytree_node=False)\n",
    "    \n",
    "    # DYNAMIC (The Sigma / Step Size)\n",
    "    pos_sigma: float = 1.0   # Move trees by ~1.0 unit\n",
    "    deg_sigma: float = 5.0   # Rotate trees by ~5.0 degrees\n",
    "    prob: float = 0.5        # Probability to move a specific tree\n",
    "\n",
    "    def _mutate_one(self, key: chex.PRNGKey, genome: ContinuousGenome, config: SantaConfig) -> ContinuousGenome:\n",
    "        k_mask, k_pos, k_deg = jax.random.split(key, 3)\n",
    "        \n",
    "        # 1. Mask: Which trees do we move?\n",
    "        # Shape: (N,) broadcasted to (N, 1)\n",
    "        mask = jax.random.bernoulli(k_mask, self.prob, (config.num_trees, 1))\n",
    "        \n",
    "        # 2. Noise Generation\n",
    "        noise_pos = jax.random.normal(k_pos, (config.num_trees, 2)) * self.pos_sigma\n",
    "        noise_deg = jax.random.normal(k_deg, (config.num_trees, 1)) * self.deg_sigma\n",
    "        \n",
    "        full_noise = jnp.concatenate([noise_pos, noise_deg], axis=1)\n",
    "        \n",
    "        # 3. Apply\n",
    "        # New = Old + (Mask * Noise)\n",
    "        new_values = genome.values + (mask * full_noise)\n",
    "        \n",
    "        # 4. Repair (Clip bounds, Wrap angles)\n",
    "        return genome.replace(values=new_values).autocorrect(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "219013b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import struct\n",
    "import chex\n",
    "from typing import Tuple, Any\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "@struct.dataclass\n",
    "class SantaConfig:\n",
    "    num_trees: int\n",
    "    min_pos: float = -100.0\n",
    "    max_pos: float = 100.0\n",
    "    scale_factor: float = 1.0\n",
    "\n",
    "# ==========================================\n",
    "# 2. THE GEOMETRIC ENGINE\n",
    "# ==========================================\n",
    "@struct.dataclass\n",
    "class JaxSantaEvaluator(BaseEvaluator[ContinuousGenome, SantaConfig, Any]):\n",
    "    \"\"\"\n",
    "    A Differentiable Geometric Evaluator for JAX.\n",
    "    Replaces Shapely with Vectorized Linear Algebra.\n",
    "    \"\"\"\n",
    "    # STATIC: The Local Coordinates of the Tree Polygon (V, 2)\n",
    "    # We bake these into the class so they are constant constants.\n",
    "    base_vertices: chex.Array = struct.field(pytree_node=True)\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, config: SantaConfig) -> \"JaxSantaEvaluator\":\n",
    "        \"\"\"Factory to initialize the tree shape.\"\"\"\n",
    "        # Define the exact vertices from the Santa 2025 code\n",
    "        # (Normalized, without the massive 1e18 scale for now)\n",
    "        trunk_w, trunk_h = 0.15, 0.2\n",
    "        base_w, mid_w, top_w = 0.7, 0.4, 0.25\n",
    "        tip_y, tier1_y, tier2_y, base_y = 0.8, 0.5, 0.25, 0.0\n",
    "        trunk_btm = -trunk_h\n",
    "\n",
    "        # Shape definition (Counter-Clockwise winding)\n",
    "        verts = [\n",
    "            [0.0, tip_y],                          # Tip\n",
    "            [top_w/2, tier1_y], [top_w/4, tier1_y], # Top Tier Right\n",
    "            [mid_w/2, tier2_y], [mid_w/4, tier2_y], # Mid Tier Right\n",
    "            [base_w/2, base_y],                    # Base Right\n",
    "            [trunk_w/2, base_y], [trunk_w/2, trunk_btm], # Trunk Right\n",
    "            [-trunk_w/2, trunk_btm], [-trunk_w/2, base_y], # Trunk Left\n",
    "            [-base_w/2, base_y],                   # Base Left\n",
    "            [-mid_w/4, tier2_y], [-mid_w/2, tier2_y], # Mid Tier Left\n",
    "            [-top_w/4, tier1_y], [-top_w/2, tier1_y]  # Top Tier Left\n",
    "        ]\n",
    "        return cls(config=config, base_vertices=jnp.array(verts))\n",
    "\n",
    "    # --- CORE MATH (Differentiable) ---\n",
    "\n",
    "    def transform_vertices(self, genome: ContinuousGenome) -> chex.Array:\n",
    "        \"\"\"\n",
    "        Transforms local tree vertices to global world coordinates.\n",
    "        Output: (Num_Trees, Num_Vertices, 2)\n",
    "        \"\"\"\n",
    "        # 1. Unpack Genome\n",
    "        # pos: (N, 2), theta: (N, 1) - degrees\n",
    "        pos = genome.values[:, :2]\n",
    "        theta_deg = genome.values[:, 2:3]\n",
    "        theta_rad = jnp.deg2rad(theta_deg)\n",
    "\n",
    "        # 2. Build Rotation Matrices (N, 2, 2)\n",
    "        # [[cos, -sin], [sin, cos]]\n",
    "        c = jnp.cos(theta_rad)\n",
    "        s = jnp.sin(theta_rad)\n",
    "        # Construct rotation matrix for each tree\n",
    "        # Shape manipulation to get (N, 2, 2)\n",
    "        row1 = jnp.concatenate([c, -s], axis=1) # (N, 2)\n",
    "        row2 = jnp.concatenate([s, c], axis=1)  # (N, 2)\n",
    "        rot_mats = jnp.stack([row1, row2], axis=1) \n",
    "\n",
    "        # 3. Apply Rotation\n",
    "        # Vertices (V, 2) -> (2, V) for matmul\n",
    "        v_T = self.base_vertices.T \n",
    "        # (N, 2, 2) @ (2, V) -> (N, 2, V)\n",
    "        rotated_T = rot_mats @ v_T\n",
    "        # Transpose back -> (N, V, 2)\n",
    "        rotated = jnp.transpose(rotated_T, (0, 2, 1))\n",
    "\n",
    "        # 4. Apply Translation\n",
    "        # Add position (N, 1, 2) broadcasted to (N, V, 2)\n",
    "        global_verts = rotated + pos[:, None, :]\n",
    "        \n",
    "        return global_verts\n",
    "\n",
    "    def calculate_bounding_score(self, vertices: chex.Array) -> float:\n",
    "        \"\"\"\n",
    "        Score = (Max_Dim_Side^2) / N\n",
    "        \"\"\"\n",
    "        # Flatten all vertices to find global min/max\n",
    "        # vertices shape: (N, V, 2) -> (N*V, 2)\n",
    "        all_points = vertices.reshape(-1, 2)\n",
    "        \n",
    "        min_xy = jnp.min(all_points, axis=0)\n",
    "        max_xy = jnp.max(all_points, axis=0)\n",
    "        \n",
    "        diffs = max_xy - min_xy\n",
    "        side_x, side_y = diffs[0], diffs[1]\n",
    "        \n",
    "        # Max dimension squared (Bounding Square Area)\n",
    "        max_side = jnp.maximum(side_x, side_y)\n",
    "        area = max_side ** 2\n",
    "        \n",
    "        return area / self.config.num_trees\n",
    "\n",
    "    def check_collisions_simple(self, genome: ContinuousGenome) -> float:\n",
    "        \"\"\"\n",
    "        A fast heuristic collision check using Bounding Circles.\n",
    "        Returns: Penalty score (0.0 = clean, >0 = collision)\n",
    "        \"\"\"\n",
    "        # Simple Logic: \n",
    "        # If distance between centers < (Radius A + Radius B), overlap likely.\n",
    "        # Tree approximate radius ~ 0.5 (Base width 0.7, Height ~1.0)\n",
    "        TREE_RADIUS = 0.45 \n",
    "        \n",
    "        pos = genome.values[:, :2] # (N, 2)\n",
    "        \n",
    "        # Calculate pairwise distances (N, N)\n",
    "        # We use squared distance to avoid Sqrt derivative issues at 0\n",
    "        diff = pos[:, None, :] - pos[None, :, :]\n",
    "        dist_sq = jnp.sum(diff**2, axis=-1)\n",
    "        \n",
    "        # Threshold: (2 * Radius)^2\n",
    "        min_dist_sq = (2 * TREE_RADIUS) ** 2\n",
    "        \n",
    "        # Mask out self-collision (diagonal)\n",
    "        # Add a large number to diagonal so it's always > min_dist\n",
    "        eye = jnp.eye(self.config.num_trees) * 1e6\n",
    "        dist_sq_masked = dist_sq + eye\n",
    "        \n",
    "        # Violation: Max(0, Threshold - Actual)\n",
    "        # If Actual < Threshold, we add penalty\n",
    "        penalties = jax.nn.relu(min_dist_sq - dist_sq_masked)\n",
    "        \n",
    "        return jnp.sum(penalties)\n",
    "\n",
    "    # --- IMPLEMENT ABSTRACT EVALUATE ---\n",
    "    \n",
    "    def evaluate(self, genome: ContinuousGenome, data: Any = None) -> float:\n",
    "        \"\"\"\n",
    "        Combined Objective Function.\n",
    "        Fitness = - (Score + Collision_Penalty * 1000)\n",
    "        \"\"\"\n",
    "        # 1. Transform Geometry\n",
    "        verts = self.transform_vertices(genome)\n",
    "        \n",
    "        # 2. Objective: Smallest Box\n",
    "        score = self.calculate_bounding_score(verts)\n",
    "        \n",
    "        # 3. Constraint: No Collisions\n",
    "        # Note: Ideally replace 'simple' with SAT for final version\n",
    "        penalty = self.check_collisions_simple(genome)\n",
    "        \n",
    "        # We minimize score, so fitness is negative\n",
    "        # Heavy weight on penalty to force valid configurations\n",
    "        total_loss = score + (penalty * 1000.0)\n",
    "        \n",
    "        return -total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06ef0241",
   "metadata": {},
   "outputs": [],
   "source": [
    "@struct.dataclass\n",
    "class SantaPopulation(BasePopulation[ContinuousGenome]):\n",
    "    \"\"\"\n",
    "    Concrete container for the Santa 2025 Optimization.\n",
    "    Wraps a batch of ContinuousGenomes (Tree Configurations).\n",
    "    \"\"\"\n",
    "    # 1. The Data\n",
    "    # Shape inside genes: (Pop_Size, Num_Trees, 3)\n",
    "    genes: ContinuousGenome\n",
    "    \n",
    "    # 2. The Scores\n",
    "    # Shape: (Pop_Size,)\n",
    "    fitness: chex.Array\n",
    "    \n",
    "    # 3. Link to the Genome Class (For the Factory)\n",
    "    GENOME_CLS: ClassVar[Type[ContinuousGenome]] = ContinuousGenome\n",
    "\n",
    "    @classmethod\n",
    "    def init_random(cls, key: chex.PRNGKey, config: SantaConfig, size: int) -> \"SantaPopulation\":\n",
    "        \"\"\"\n",
    "        Creates a population of random tree configurations.\n",
    "        \"\"\"\n",
    "        # 1. Use the Base Factory (Vectorized)\n",
    "        # Calls ContinuousGenome.create_population -> vmap(random_init)\n",
    "        batched_genes = ContinuousGenome.create_population(key, config, size)\n",
    "        \n",
    "        # 2. Initialize Fitness (Negative Infinity)\n",
    "        initial_fitness = jnp.full((size,), -jnp.inf)\n",
    "        \n",
    "        return cls(genes=batched_genes, fitness=initial_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aed9eae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population Size: 10000\n",
      "Gene Shape: (10000, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "# 1. Define the Challenge\n",
    "config = SantaConfig(\n",
    "    num_trees=50,       # We want to pack 50 trees\n",
    "    min_pos=-100.0,     # The 100x100 meter bounds\n",
    "    max_pos=100.0\n",
    ")\n",
    "\n",
    "# 2. Setup Randomness\n",
    "master_key = jax.random.PRNGKey(2025)\n",
    "\n",
    "# 3. Create the Instance\n",
    "# This creates 10,000 distinct configurations of 50 trees each.\n",
    "# Total Matrix Size: (10000, 50, 3) floats\n",
    "xmas_tree_population = SantaPopulation.init_random(\n",
    "    key=master_key, \n",
    "    config=config, \n",
    "    size=10000\n",
    ")\n",
    "\n",
    "# 4. Verify\n",
    "print(f\"Population Size: {len(xmas_tree_population)}\")\n",
    "print(f\"Gene Shape: {xmas_tree_population.genes.values.shape}\")\n",
    "# Output: (10000, 50, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42ddb8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@struct.dataclass\n",
    "class GaussianMutation(BaseMutation[ContinuousGenome, SantaConfig]):\n",
    "    \"\"\"\n",
    "    Applies Gaussian noise to tree positions and rotations.\n",
    "    \"\"\"\n",
    "    # STATIC\n",
    "    num_offspring: int = struct.field(pytree_node=False, default=1)\n",
    "    \n",
    "    # DYNAMIC (Tunable Noise Levels)\n",
    "    prob: float = 0.5        # Probability to nudge a specific tree\n",
    "    pos_sigma: float = 2.0   # Standard deviation for X/Y (e.g., 2 meters)\n",
    "    deg_sigma: float = 10.0  # Standard deviation for Angle (e.g., 10 degrees)\n",
    "\n",
    "    def _mutate_one(self, key: chex.PRNGKey, genome: ContinuousGenome, config: SantaConfig) -> ContinuousGenome:\n",
    "        k_mask, k_noise = jax.random.split(key)\n",
    "        \n",
    "        # 1. Mask: Which trees get nudged?\n",
    "        # Shape: (N,) -> Broadcast to (N, 1) to cover x,y,theta columns\n",
    "        mask = jax.random.bernoulli(k_mask, self.prob, (config.num_trees, 1))\n",
    "        \n",
    "        # 2. Noise: Generate different scales for Pos vs Angle\n",
    "        # Noise Shape: (N, 3)\n",
    "        # We split the key again to handle the noise generation\n",
    "        noise_vals = jax.random.normal(k_noise, (config.num_trees, 3))\n",
    "        \n",
    "        # Scale columns independently: [x*pos_sigma, y*pos_sigma, deg*deg_sigma]\n",
    "        # Create a scale vector: (1, 3)\n",
    "        scales = jnp.array([[self.pos_sigma, self.pos_sigma, self.deg_sigma]])\n",
    "        scaled_noise = noise_vals * scales\n",
    "        \n",
    "        # 3. Apply\n",
    "        # New = Old + (Mask * Noise)\n",
    "        new_values = genome.values + (mask * scaled_noise)\n",
    "        \n",
    "        # 4. Repair (Clip to bounds, wrap 360)\n",
    "        return genome.replace(values=new_values).autocorrect(config)\n",
    "\n",
    "\n",
    "@struct.dataclass\n",
    "class ContinuousCrossover(BaseCrossover[ContinuousGenome, SantaConfig]):\n",
    "    \"\"\"\n",
    "    Uniform Crossover for Continuous Genomes.\n",
    "    Swaps entire trees (x, y, theta) between parents.\n",
    "    \"\"\"\n",
    "    # STATIC\n",
    "    num_offspring: int = struct.field(pytree_node=False, default=1)\n",
    "    \n",
    "    # DYNAMIC\n",
    "    mixing_ratio: float = 0.5\n",
    "\n",
    "    def _cross_one(self, key: chex.PRNGKey, p1: ContinuousGenome, p2: ContinuousGenome, config: SantaConfig) -> ContinuousGenome:\n",
    "        # 1. Mask: Decide per tree (row)\n",
    "        mask = jax.random.bernoulli(key, self.mixing_ratio, (config.num_trees,))\n",
    "        \n",
    "        # 2. Broadcast mask to columns (N,) -> (N, 3)\n",
    "        mask_bcast = mask[:, None]\n",
    "        \n",
    "        # 3. Swap Rows\n",
    "        child_values = jnp.where(mask_bcast, p2.values, p1.values)\n",
    "        \n",
    "        return p1.replace(values=child_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b57370b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Santa 2025 Operator Demo ===\n",
      "\n",
      "1. Creating Parent...\n",
      "   Parent Values (First 2 trees):\n",
      "[[-2.1969557e-01 -5.7836461e+00  3.3885193e+02]\n",
      " [-6.0277677e+00  3.3743358e+00  1.6650845e+02]]\n",
      "\n",
      "2. Applying High-Noise Mutation...\n",
      "   Mutant Values:\n",
      "[[ 10.       -10.       300.43704 ]\n",
      " [-10.        -9.035362 209.87344 ]]\n",
      "   Max Position Absolute Value: 10.00 (Should be <= 10.0)\n",
      "   [PASS] Autocorrect enforced bounds.\n",
      "\n",
      "3. Applying Crossover...\n",
      "   Rows inherited from Parent 1: 1 / 5\n",
      "   [PASS] Crossover mixed parents.\n"
     ]
    }
   ],
   "source": [
    "def run_continuous_variation_demo():\n",
    "    print(\"=== Santa 2025 Operator Demo ===\\n\")\n",
    "    \n",
    "    # 1. SETUP (Tiny Config for readability)\n",
    "    # 5 Trees, strict bounds [-10, 10] to test clipping easily\n",
    "    config = SantaConfig(num_trees=5, min_pos=-10.0, max_pos=10.0)\n",
    "    key = jax.random.PRNGKey(2025)\n",
    "\n",
    "    # 2. INIT PARENT\n",
    "    print(\"1. Creating Parent...\")\n",
    "    parent = ContinuousGenome.random_init(key, config)\n",
    "    print(f\"   Parent Values (First 2 trees):\\n{parent.values[:2]}\")\n",
    "\n",
    "    # 3. TEST MUTATION (High Noise to force clipping)\n",
    "    print(\"\\n2. Applying High-Noise Mutation...\")\n",
    "    # pos_sigma=20.0 means noise can easily push values outside [-10, 10]\n",
    "    mutator = GaussianMutation(num_offspring=1, prob=1.0, pos_sigma=20.0, deg_sigma=45.0)\n",
    "    \n",
    "    @jax.jit\n",
    "    def run_mut(k, g): return mutator(k, g, config)\n",
    "    \n",
    "    # We use slice [0] because num_offspring=1 returns a batch of 1\n",
    "    mutant = jax.tree_util.tree_map(lambda x: x[0], run_mut(jax.random.PRNGKey(1), parent))\n",
    "    \n",
    "    print(f\"   Mutant Values:\\n{mutant.values[:2]}\")\n",
    "    \n",
    "    # VERIFY BOUNDS\n",
    "    max_val = jnp.max(jnp.abs(mutant.values[:, :2]))\n",
    "    print(f\"   Max Position Absolute Value: {max_val:.2f} (Should be <= 10.0)\")\n",
    "    assert max_val <= 10.001, \"Autocorrect Failed! Bounds violated.\"\n",
    "    print(\"   [PASS] Autocorrect enforced bounds.\")\n",
    "\n",
    "    # 4. TEST CROSSOVER\n",
    "    print(\"\\n3. Applying Crossover...\")\n",
    "    parent2 = ContinuousGenome.random_init(jax.random.PRNGKey(2), config)\n",
    "    crossover = ContinuousCrossover(num_offspring=1, mixing_ratio=0.5)\n",
    "    \n",
    "    @jax.jit\n",
    "    def run_cross(k, a, b): return crossover(k, a, b, config)\n",
    "    \n",
    "    child = jax.tree_util.tree_map(lambda x: x[0], run_cross(jax.random.PRNGKey(3), parent, parent2))\n",
    "    \n",
    "    # Check if we have a mix\n",
    "    # We count how many rows match P1 exactly\n",
    "    matches_p1 = jnp.sum(jnp.all(child.values == parent.values, axis=1))\n",
    "    print(f\"   Rows inherited from Parent 1: {matches_p1} / 5\")\n",
    "    print(\"   [PASS] Crossover mixed parents.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_continuous_variation_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86338c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@struct.dataclass\n",
    "class TournamentSelection(BaseSelection):\n",
    "    \"\"\"\n",
    "    Standard Tournament Selection.\n",
    "    Selects 'num_selections' parents by holding 'num_selections' tournaments.\n",
    "    \"\"\"\n",
    "    # STATIC CONFIG\n",
    "    tournament_size: int = struct.field(pytree_node=False, default=3)\n",
    "\n",
    "    def __call__(self, key: chex.PRNGKey, fitness: chex.Array) -> chex.Array:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            key: RNG Key\n",
    "            fitness: Shape (Pop_Size,) - Scalar fitness per individual\n",
    "            \n",
    "        Returns:\n",
    "            indices: Shape (num_selections,) - Indices of the winning GENOMES.\n",
    "        \"\"\"\n",
    "        pop_size = fitness.shape[0]\n",
    "        \n",
    "        # 1. Generate Random Contenders\n",
    "        # Shape: (Num_Selections, Tournament_Size)\n",
    "        # We need 'num_selections' tournaments, each with 'k' participants\n",
    "        k_tourn = jax.random.split(key)[0]\n",
    "        contestants = jax.random.randint(\n",
    "            k_tourn, \n",
    "            shape=(self.num_selections, self.tournament_size), \n",
    "            minval=0, \n",
    "            maxval=pop_size\n",
    "        )\n",
    "        \n",
    "        # 2. Look up Fitness\n",
    "        # Gather the scores of every contestant\n",
    "        # Shape: (Num_Selections, Tournament_Size)\n",
    "        scores = jnp.take(fitness, contestants)\n",
    "        \n",
    "        # 3. Find Winners\n",
    "        # Argmax gives us the LOCAL index (0..k-1) of the winner in each tournament\n",
    "        winner_local_idx = jnp.argmax(scores, axis=1)\n",
    "        \n",
    "        # 4. Map back to Global Index\n",
    "        # We select the actual Population Index of the winner\n",
    "        winner_indices = jax.vmap(\n",
    "            lambda row, idx: row[idx]\n",
    "        )(contestants, winner_local_idx)\n",
    "        \n",
    "        return winner_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9417c819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import struct\n",
    "import chex\n",
    "from typing import Type, TypeVar, Generic, Any\n",
    "\n",
    "# Generic variable for the Genome (Linear, Continuous, Tree...)\n",
    "G = TypeVar(\"G\", bound=\"BaseGenome\")\n",
    "\n",
    "@struct.dataclass\n",
    "class EvolutionState(Generic[G]):\n",
    "    \"\"\"\n",
    "    The State of the World.\n",
    "    This Pytree is passed in/out of the JAX scan loop.\n",
    "    \"\"\"\n",
    "    # 1. The Current Generation\n",
    "    # Contains (N) Genomes and (N) Fitness scores\n",
    "    population: \"BasePopulation[G]\"\n",
    "\n",
    "    # 2. The Hall of Fame (Global Best)\n",
    "    # We track this separately because the current population might \n",
    "    # drift away from the optimum due to high mutation/exploration.\n",
    "    # This is a SINGLE genome (unbatched).\n",
    "    best_genome: G\n",
    "    best_fitness: chex.Array  # Scalar (float32)\n",
    "\n",
    "    # 3. Randomness State\n",
    "    # The key for the *next* generation's operations\n",
    "    key: chex.PRNGKey\n",
    "\n",
    "    # 4. Metadata\n",
    "    gen_counter: chex.Array   # Scalar (int32)\n",
    "\n",
    "    @classmethod\n",
    "    def create(\n",
    "        cls, \n",
    "        pop_class: Type[\"BasePopulation[G]\"], \n",
    "        config: Any, \n",
    "        key: chex.PRNGKey, \n",
    "        pop_size: int\n",
    "    ) -> \"EvolutionState[G]\":\n",
    "        \"\"\"\n",
    "        Factory to initialize the state at Generation 0.\n",
    "        \"\"\"\n",
    "        k_pop, k_state = jax.random.split(key)\n",
    "\n",
    "        # A. Initialize Random Population\n",
    "        # We rely on the Abstract Factory we built in BasePopulation\n",
    "        initial_pop = pop_class.init_random(k_pop, config, pop_size)\n",
    "\n",
    "        # B. Initialize Global Best (Placeholder)\n",
    "        # We grab the first individual from the batch to serve as the placeholder \"best\".\n",
    "        # We rely on the 'Kebab' __getitem__[0] we implemented earlier.\n",
    "        first_genome = initial_pop[0]\n",
    "\n",
    "        return cls(\n",
    "            population=initial_pop,\n",
    "            best_genome=first_genome,\n",
    "            # Start with -inf so the first evaluation will overwrite this\n",
    "            best_fitness=jnp.array(-jnp.inf, dtype=jnp.float32),\n",
    "            key=k_state,\n",
    "            gen_counter=jnp.array(0, dtype=jnp.int32)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9b8577f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ðŸŽ… Santa 2025: Continuous Optimization Solver ===\n",
      "\n",
      "Configuration: 50 Trees\n",
      "Population:    2000\n",
      "Generations:   1000\n",
      "----------------------------------------\n",
      "Initializing Population on GPU... Done.\n",
      "Initial Score: 621.5767\n",
      "Compiling Evolution Loop (XLA)... "
     ]
    },
    {
     "ename": "ConcretizationTypeError",
     "evalue": "Abstract tracer value encountered where concrete value is expected: traced array with shape float32[]\nThe problem arose with the `int` function. If trying to convert the data type of a value, try using `x.astype(int)` or `jnp.array(x, int)` instead.\nThe error occurred while tracing the function step at /var/folders/n8/08b2nd114jdfnsydb_4mj4fw0000gn/T/ipykernel_38319/581938587.py:27 for jit. This concrete value was not available in Python because it depends on the value of the argument self.elitism_rate.\n\nSee https://docs.jax.dev/en/latest/errors.html#jax.errors.ConcretizationTypeError",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConcretizationTypeError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 174\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;66;03m# Run compilation\u001b[39;00m\n\u001b[32m    173\u001b[39m start_compile = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m final_state, history = \u001b[43mjax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscan_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m=\u001b[49m\u001b[43mGENERATIONS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[38;5;66;03m# Block until ready to measure compile time\u001b[39;00m\n\u001b[32m    176\u001b[39m _ = final_state.best_fitness.block_until_ready()\n",
      "    \u001b[31m[... skipping hidden 10 frame]\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 168\u001b[39m, in \u001b[36mscan_body\u001b[39m\u001b[34m(carry_state, _)\u001b[39m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mscan_body\u001b[39m(carry_state, _):\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m     new_state = \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcarry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# Log metrics (we return them to host)\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m new_state, new_state.best_fitness\n",
      "    \u001b[31m[... skipping hidden 13 frame]\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mGeneticEngine.step\u001b[39m\u001b[34m(self, state)\u001b[39m\n\u001b[32m     37\u001b[39m k_sel, k_cross, k_mut, k_next = jax.random.split(key, \u001b[32m4\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# 2. Elitism (Preserve top 5%)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m num_elites = \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpop_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43melitism_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# We need negative fitness for top_k because we want largest values (least negative)\u001b[39;00m\n\u001b[32m     42\u001b[39m _, elite_indices = jax.lax.top_k(pop.fitness, num_elites)\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/GP_env/lib/python3.12/site-packages/jax/_src/core.py:1811\u001b[39m, in \u001b[36mconcretization_function_error.<locals>.error\u001b[39m\u001b[34m(self, arg)\u001b[39m\n\u001b[32m   1810\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34merror\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg):\n\u001b[32m-> \u001b[39m\u001b[32m1811\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ConcretizationTypeError(arg, fname_context)\n",
      "\u001b[31mConcretizationTypeError\u001b[39m: Abstract tracer value encountered where concrete value is expected: traced array with shape float32[]\nThe problem arose with the `int` function. If trying to convert the data type of a value, try using `x.astype(int)` or `jnp.array(x, int)` instead.\nThe error occurred while tracing the function step at /var/folders/n8/08b2nd114jdfnsydb_4mj4fw0000gn/T/ipykernel_38319/581938587.py:27 for jit. This concrete value was not available in Python because it depends on the value of the argument self.elitism_rate.\n\nSee https://docs.jax.dev/en/latest/errors.html#jax.errors.ConcretizationTypeError"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import struct\n",
    "import chex\n",
    "from typing import Any, Tuple\n",
    "import time\n",
    "\n",
    "# --- ASSUMING PREVIOUS CLASSES ARE IMPORTED ---\n",
    "# (In a real project, these would be: from core import ...)\n",
    "# For this script to be standalone copy-paste, I will include the missing \n",
    "# GeneticEngine wiring we discussed.\n",
    "\n",
    "@struct.dataclass\n",
    "class GeneticEngine:\n",
    "    # 1. The Logic Units\n",
    "    evaluator: Any # Typed as BaseEvaluator\n",
    "    selection: Any # Typed as BaseSelection\n",
    "    crossover: Any # Typed as BaseCrossover\n",
    "    mutation: Any  # Typed as BaseMutation\n",
    "    \n",
    "    # 2. Hyperparameters\n",
    "    elitism_rate: float = 0.05\n",
    "\n",
    "    def init_state(self, config: Any, key: chex.PRNGKey, pop_size: int) -> EvolutionState:\n",
    "        return EvolutionState.create(SantaPopulation, config, key, pop_size)\n",
    "\n",
    "    @jax.jit\n",
    "    def step(self, state: EvolutionState) -> EvolutionState:\n",
    "        \"\"\"\n",
    "        One Generation Step: Select -> Cross -> Mutate -> Evaluate -> Merge\n",
    "        \"\"\"\n",
    "        pop = state.population\n",
    "        pop_size = pop.fitness.shape[0]\n",
    "        key = state.key\n",
    "        \n",
    "        # 1. Manage Randomness\n",
    "        k_sel, k_cross, k_mut, k_next = jax.random.split(key, 4)\n",
    "\n",
    "        # 2. Elitism (Preserve top 5%)\n",
    "        num_elites = int(pop_size * self.elitism_rate)\n",
    "        # We need negative fitness for top_k because we want largest values (least negative)\n",
    "        _, elite_indices = jax.lax.top_k(pop.fitness, num_elites)\n",
    "        elites = pop[elite_indices]\n",
    "\n",
    "        # 3. Selection (Tournament)\n",
    "        # We perform tournament selection to find parents for the next generation\n",
    "        parent_indices = self.selection(k_sel, pop.fitness)\n",
    "        parents = pop[parent_indices]\n",
    "\n",
    "        # 4. Crossover (Mix Parents)\n",
    "        # Shuffle parents to create pairs\n",
    "        p1 = parents\n",
    "        p2_indices = jax.random.permutation(k_cross, jnp.arange(pop_size))\n",
    "        p2 = parents[p2_indices]\n",
    "        \n",
    "        offspring_genes = self.crossover(k_cross, p1.genes, p2.genes, self.evaluator.config)\n",
    "        # Flatten batch dimension if necessary (here assuming num_offspring=1)\n",
    "        offspring_genes = jax.tree_util.tree_map(lambda x: x.squeeze(1), offspring_genes)\n",
    "\n",
    "        # 5. Mutation (Add Noise)\n",
    "        # Mutate the crossed-over children\n",
    "        mutant_genes = self.mutation(k_mut, offspring_genes, self.evaluator.config)\n",
    "        mutant_genes = jax.tree_util.tree_map(lambda x: x.squeeze(1), mutant_genes)\n",
    "\n",
    "        # 6. Merge & Truncate\n",
    "        # We have Pop_Size mutants, but we need to make space for Elites\n",
    "        num_mutants_needed = pop_size - num_elites\n",
    "        \n",
    "        # Take the first N mutants\n",
    "        mutants_to_keep = jax.tree_util.tree_map(lambda x: x[:num_mutants_needed], mutant_genes)\n",
    "        \n",
    "        # Concatenate Elites + Mutants\n",
    "        new_genes = jax.tree_util.tree_map(\n",
    "            lambda e, m: jnp.concatenate([e, m], axis=0),\n",
    "            elites.genes.values, # Access inner array\n",
    "            mutants_to_keep.values\n",
    "        )\n",
    "        # Wrap back into Genome object\n",
    "        new_genome_batch = ContinuousGenome(values=new_genes)\n",
    "        \n",
    "        # Create new Population container (Fitness not calculated yet)\n",
    "        next_gen_pop = SantaPopulation(\n",
    "            genes=new_genome_batch, \n",
    "            fitness=jnp.full((pop_size,), -jnp.inf)\n",
    "        )\n",
    "\n",
    "        # 7. Evaluate\n",
    "        evaluated_pop = self.evaluator.evaluate_population(next_gen_pop, data=None)\n",
    "\n",
    "        # 8. Update Hall of Fame (Global Best)\n",
    "        best_idx = jnp.argmax(evaluated_pop.fitness)\n",
    "        current_best_fit = evaluated_pop.fitness[best_idx]\n",
    "        current_best_genome = evaluated_pop[best_idx]\n",
    "\n",
    "        is_new_record = current_best_fit > state.best_fitness\n",
    "        \n",
    "        new_best_genome = jax.tree_util.tree_map(\n",
    "            lambda old, new: jnp.where(is_new_record, new, old),\n",
    "            state.best_genome,\n",
    "            current_best_genome\n",
    "        )\n",
    "        new_best_fit = jnp.maximum(state.best_fitness, current_best_fit)\n",
    "\n",
    "        return EvolutionState(\n",
    "            population=evaluated_pop,\n",
    "            best_genome=new_best_genome,\n",
    "            best_fitness=new_best_fit,\n",
    "            key=k_next,\n",
    "            gen_counter=state.gen_counter + 1\n",
    "        )\n",
    "\n",
    "# --- EXECUTION SCRIPT ---\n",
    "\n",
    "print(\"=== ðŸŽ… Santa 2025: Continuous Optimization Solver ===\\n\")\n",
    "\n",
    "# 1. SETUP\n",
    "# Challenge: Pack 50 trees into the smallest square possible\n",
    "config = SantaConfig(num_trees=50, min_pos=-100.0, max_pos=100.0)\n",
    "\n",
    "# Engine Hyperparameters\n",
    "POP_SIZE = 2000       # 2,000 Parallel Configurations\n",
    "GENERATIONS = 1000    # 1,000 Iterations\n",
    "\n",
    "print(f\"Configuration: {config.num_trees} Trees\")\n",
    "print(f\"Population:    {POP_SIZE}\")\n",
    "print(f\"Generations:   {GENERATIONS}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 2. INITIALIZE COMPONENTS\n",
    "# Evaluator (The Geometry Engine)\n",
    "evaluator = JaxSantaEvaluator.create(config)\n",
    "\n",
    "# Operators (The Evolution Logic)\n",
    "# Using 'Explosive' parameters? No, let's use standard evolution first.\n",
    "selection = TournamentSelection(num_selections=POP_SIZE, tournament_size=5)\n",
    "crossover = ContinuousCrossover(num_offspring=1, mixing_ratio=0.5)\n",
    "# Adaptive Mutation: 50% chance to move a tree, sigma=1.0m, rotation=5deg\n",
    "mutation = GaussianMutation(num_offspring=1, prob=0.5, pos_sigma=1.0, deg_sigma=5.0)\n",
    "\n",
    "engine = GeneticEngine(\n",
    "    evaluator=evaluator,\n",
    "    selection=selection,\n",
    "    crossover=crossover,\n",
    "    mutation=mutation,\n",
    "    elitism_rate=0.05\n",
    ")\n",
    "\n",
    "# 3. INITIALIZE STATE\n",
    "print(\"Initializing Population on GPU...\", end=\" \")\n",
    "master_key = jax.random.PRNGKey(2025)\n",
    "state = engine.init_state(config, master_key, POP_SIZE)\n",
    "\n",
    "# Run one evaluation to get initial best\n",
    "state = state.replace(population=evaluator.evaluate_population(state.population, None))\n",
    "# Update best manually for gen 0\n",
    "best_idx = jnp.argmax(state.population.fitness)\n",
    "state = state.replace(\n",
    "    best_genome=state.population[best_idx],\n",
    "    best_fitness=state.population.fitness[best_idx]\n",
    ")\n",
    "print(f\"Done.\\nInitial Score: {-state.best_fitness:.4f}\")\n",
    "\n",
    "# 4. COMPILE THE LOOP\n",
    "print(\"Compiling Evolution Loop (XLA)...\", end=\" \")\n",
    "\n",
    "# We use scan to run the loop entirely on the accelerator\n",
    "def scan_body(carry_state, _):\n",
    "    new_state = engine.step(carry_state)\n",
    "    # Log metrics (we return them to host)\n",
    "    return new_state, new_state.best_fitness\n",
    "\n",
    "# Run compilation\n",
    "start_compile = time.time()\n",
    "final_state, history = jax.lax.scan(scan_body, state, None, length=GENERATIONS)\n",
    "# Block until ready to measure compile time\n",
    "_ = final_state.best_fitness.block_until_ready()\n",
    "print(f\"Done ({time.time() - start_compile:.2f}s)\")\n",
    "\n",
    "# 5. ANALYSIS\n",
    "print(\"-\" * 40)\n",
    "print(\"Optimization Finished.\")\n",
    "\n",
    "final_score = -final_state.best_fitness\n",
    "print(f\"Final Score: {final_score:.4f}\")\n",
    "\n",
    "# Calculate improvement\n",
    "initial_score = -state.best_fitness\n",
    "improvement = ((initial_score - final_score) / initial_score) * 100\n",
    "print(f\"Improvement: {improvement:.2f}%\")\n",
    "\n",
    "# 6. VISUALIZATION (Text Based)\n",
    "best_genome = final_state.best_genome\n",
    "print(\"\\nBest Configuration (First 3 Trees):\")\n",
    "print(\"   X      |    Y     |  Angle\")\n",
    "print(\"-\" * 30)\n",
    "for i in range(3):\n",
    "    row = best_genome.values[i]\n",
    "    print(f\"{row[0]:7.2f} | {row[1]:7.2f} | {row[2]:6.1f}Â°\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcf6113",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GP_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
