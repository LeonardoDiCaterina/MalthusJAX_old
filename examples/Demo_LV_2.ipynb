{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd31e4e4",
   "metadata": {},
   "source": [
    "# MalthusJAX Level 2 Showcase: Operators\n",
    "This notebook demonstrates the core **Level 2** components of MalthusJAX:\n",
    "\n",
    "- **AbstractSelectionOperator**\n",
    "- **AbstractMutationOperator**\n",
    "- **AbstractCrossoverOperator**\n",
    "\n",
    "### Key Design Pattern: The Factory Pattern\n",
    "\n",
    "1. **Instantiation**: Create an Operator Class with static configuration (e.g., `mutation_rate`).\n",
    "2. **Compilation**: Call `.get_compiled_function()` to obtain a pure, JIT-compiled JAX function.\n",
    "3. **Population-Wide Execution**: Use `jax.vmap` to apply this pure function across entire populations (JAX arrays).\n",
    "\n",
    "---\n",
    "\n",
    "### Workflow Overview\n",
    "\n",
    "#### 1: Introduction & Setup\n",
    "- Import necessary components:\n",
    "    - `jax` and `jax.numpy`\n",
    "    - Level 1 components (Genomes and Fitness functions) for demo population creation\n",
    "    - Refactored Level 2 Operator classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29212a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os\n",
    "import time\n",
    "# Add the src directory to the path so we can import malthusjax\n",
    "sys.path.append('/Users/leonardodicaterina/Documents/GitHub/MalthusJAX/src')\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jar\n",
    "from jax import random, jit, vmap\n",
    "\n",
    "from malthusjax.core.fitness.binary_ones import BinarySumFitnessEvaluator\n",
    "from malthusjax.core.base import JAXTensorizable\n",
    "from malthusjax.core.fitness.base import AbstractFitnessEvaluator\n",
    "from malthusjax.core.genome.base import AbstractGenome, AbstractGenomeConfig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab3b0440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX running on: cpu\n"
     ]
    }
   ],
   "source": [
    "# --- Imports ---\n",
    "import functools\n",
    "from typing import Callable, List, Dict, Any, Tuple\n",
    "\n",
    "print(f\"JAX running on: {jax.default_backend()}\")\n",
    "\n",
    "# --- JAX Setup ---\n",
    "# Master PRNG Key\n",
    "key = random.PRNGKey(42)\n",
    "\n",
    "# --- Level 1 Imports (from our previous work) ---\n",
    "# Genomes\n",
    "from malthusjax.core.genome.binary import BinaryGenome, BinaryGenomeConfig\n",
    "from malthusjax.core.genome.real import RealGenome, RealGenomeConfig\n",
    "#from malthusjax.core.genome.permutation import PermutationGenome # Assuming this exists\n",
    "from malthusjax.core.genome.categorical import CategoricalGenome, CategoricalGenomeConfig\n",
    "\n",
    "# Fitness\n",
    "from malthusjax.core.fitness.binary_ones import BinarySumFitnessEvaluator\n",
    "from malthusjax.core.fitness.real import SphereFitnessEvaluator\n",
    "\n",
    "# --- Level 2 Imports (NEW) ---\n",
    "# Base classes (for type hints)\n",
    "from malthusjax.operators.base import AbstractGeneticOperator\n",
    "from malthusjax.operators.selection.base import AbstractSelectionOperator\n",
    "from malthusjax.operators.mutation.base import AbstractMutation\n",
    "from malthusjax.operators.crossover.base import AbstractCrossover\n",
    "\n",
    "# Selection Operators\n",
    "from malthusjax.operators.selection.tournament import TournamentSelection\n",
    "from malthusjax.operators.selection.roulette import RouletteSelection\n",
    "\n",
    "# Binary Operators\n",
    "from malthusjax.operators.mutation.binary import BitFlipMutation, SwapMutation as BinarySwap\n",
    "from malthusjax.operators.crossover.binary import UniformCrossover as BinaryUniform, SinglePointCrossover as BinarySinglePoint\n",
    "\n",
    "# Real Operators\n",
    "from malthusjax.operators.mutation.real import BallMutation\n",
    "from malthusjax.operators.crossover.real import UniformCrossover as RealUniform, SinglePointCrossover as RealSinglePoint, AverageCrossover\n",
    "\n",
    "# Permutation Operators\n",
    "from malthusjax.operators.mutation.permutation import ScrambleMutation, SwapMutation as PermutationSwap\n",
    "from malthusjax.operators.crossover.permutation import CycleCrossover, PillarCrossover\n",
    "\n",
    "# Categorical Operators\n",
    "from malthusjax.operators.mutation.categorical import CategoricalFlipMutation\n",
    "from malthusjax.operators.crossover.categorical import UniformCrossover as CatUniform, SinglePointCrossover as CatSinglePoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b903c4b",
   "metadata": {},
   "source": [
    "## 2. The AbstractFitnessEvaluator\n",
    "\n",
    "The **AbstractFitnessEvaluator** is designed to define the logic for evaluating a single genome tensor. With MalthusJAX, batch evaluation (via `vmap`) is automatically handled, simplifying the process.\n",
    "\n",
    "### Key Concept:\n",
    "You need to implement the following method:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68bcd2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling random initialization function with array_shape=(20,), p=0.5\n",
      "Created population tensors with shape: (100, 20)\n",
      "Data type: bool\n",
      "\n",
      "Calculated fitness values (shape (100,)):\n",
      "[ 8 14  8  9  8 14 11 12 10 15  8  8  9 11  9  7 11  9 10  9 11 12 11 13\n",
      " 10  9 10 10  9  9 11  7 11  8 11  9  9 11  9 13 13 10 10  6  8 13  9  9\n",
      " 11 13  8  8 12 14 13  7 10 14  9  9 10 10 10 12 16  6  7  9 11  9 10  6\n",
      "  6 13  9 10  9  9 11  9 10  9  7 13 10  7 13 12 11  9 12 12 12 15 11 13\n",
      " 11 12  9  9]\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Define Population and Problem ---\n",
    "POP_SIZE = 100\n",
    "GENOME_LENGTH = 20\n",
    "\n",
    "key, init_key, fitness_key = random.split(key, 3)\n",
    "\n",
    "# --- 2. Create Population ---\n",
    "# Get the JIT-able init function from the Genome class\n",
    "bin_config = BinaryGenomeConfig(array_shape=(GENOME_LENGTH,), p=0.5)\n",
    "init_fn = BinaryGenome.get_random_initialization_compilable_from_config(bin_config)\n",
    "\n",
    "# vmap it to create a population\n",
    "pop_init_fn = jit(vmap(init_fn))\n",
    "\n",
    "# Create population\n",
    "init_keys = random.split(init_key, POP_SIZE)\n",
    "population_tensors = pop_init_fn(init_keys)\n",
    "\n",
    "print(f\"Created population tensors with shape: {population_tensors.shape}\")\n",
    "print(f\"Data type: {population_tensors.dtype}\")\n",
    "\n",
    "\n",
    "# --- 3. Evaluate Fitness ---\n",
    "# Get the JIT-able fitness function\n",
    "sum_evaluator = BinarySumFitnessEvaluator()\n",
    "fitness_fn = sum_evaluator.get_tensor_fitness_function()\n",
    "\n",
    "# vmap it to evaluate the population\n",
    "# (Note: sum_evaluator.evaluate_batch() does this automatically,\n",
    "# but we do it manually here to show the pure-function pattern)\n",
    "pop_fitness_fn = jit(vmap(fitness_fn))\n",
    "\n",
    "fitness_values = pop_fitness_fn(population_tensors)\n",
    "\n",
    "print(f\"\\nCalculated fitness values (shape {fitness_values.shape}):\")\n",
    "print(fitness_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe7e507",
   "metadata": {},
   "source": [
    "### Auto-Vectorization with `vmap`\n",
    "\n",
    "One of the most powerful features of MalthusJAX is **auto-vectorization**. The `evaluate_batch` method in the base class leverages `jax.vmap` to seamlessly create a batched version of the tensor function.\n",
    "\n",
    "#### Why is this important?\n",
    "- **Efficiency**: Evaluate an entire population in parallel on the accelerator.\n",
    "- **Simplicity**: A single method call handles the batch evaluation for you.\n",
    "\n",
    "With this approach, you can process large populations effortlessly, unlocking the full potential of JAX's high-performance capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6330fdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tournament Selection ---\n",
      "Original fitnesses (top 10): [13 13 13 14 14 14 14 15 15 16]\n",
      "\n",
      "Selected indices (shape (100,)):\n",
      "[53 37 83  9 49 49 90 30 93 94 34  6 13 62 64 42 88 64 86 18 92 49  9 23\n",
      "  5 88 83 54 86 23 86 73 86 21 74 30 94 61 21 40 83 57 40 21 94 62  9 64\n",
      " 83 53 68 48 63 75 86 87 27 54 90  1  5 73 54 23  7  6 23 52 57 57 13 64\n",
      " 97 63 83  1 18  1 90 63 80 45 49 48 75 40 40 21 95  8 36 83 64  5 61  5\n",
      " 45 87 64 23]\n",
      "\n",
      "Fitnesses of selected (top 10): [15 15 15 15 16 16 16 16 16 16]\n",
      "Average fitness BEFORE selection: 10.179999351501465\n",
      "Average fitness AFTER selection: 12.460000038146973\n",
      "\n",
      "Shape of new parent population: (100, 20)\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Setup Selection ---\n",
    "print(\"--- Tournament Selection ---\")\n",
    "key, select_key = random.split(key)\n",
    "\n",
    "# Ensure POP_SIZE is a static Python integer\n",
    "pop_size = int(POP_SIZE)\n",
    "\n",
    "# We want to select POP_SIZE individuals to create the next generation\n",
    "# (allowing duplicates, as tournament selection does)\n",
    "tourn_op_factory = TournamentSelection(\n",
    "    number_of_choices=pop_size,\n",
    "    tournament_size=4\n",
    ")\n",
    "\n",
    "# --- 2. Get the JIT-compiled function ---\n",
    "# This is a pure function we can use in our main loop\n",
    "\n",
    "select_fn = tourn_op_factory.get_compiled_function()\n",
    "# --- 3. Run Selection ---\n",
    "# Pass in the key and the fitness values\n",
    "\n",
    "selected_indices = select_fn(select_key, fitness_values)\n",
    "\n",
    "print(f\"Original fitnesses (top 10): {jnp.sort(fitness_values)[-10:]}\")\n",
    "print(f\"\\nSelected indices (shape {selected_indices.shape}):\\n{selected_indices}\")\n",
    "\n",
    "# Prove that selection worked:\n",
    "selected_fitnesses = fitness_values[selected_indices]\n",
    "print(f\"\\nFitnesses of selected (top 10): {jnp.sort(selected_fitnesses)[-10:]}\")\n",
    "print(f\"Average fitness BEFORE selection: {jnp.mean(fitness_values)}\")\n",
    "print(f\"Average fitness AFTER selection: {jnp.mean(selected_fitnesses)}\")\n",
    "\n",
    "# --- 4. Get the Parent Population ---\n",
    "# In the main GA loop, we'd use these indices to get the new population\n",
    "parent_population = population_tensors[selected_indices]\n",
    "print(f\"\\nShape of new parent population: {parent_population.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e03813",
   "metadata": {},
   "source": [
    "Example 2: KnapsackFitnessEvaluator\n",
    "This evaluator shows how to pass static arguments (weights, values, limits) into the JIT-compiled function using functools.partial. The get_tensor_fitness_function returns a closure that already knows about these static values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22db27d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- BitFlip Mutation ---\n",
      "mutation_mask shape: (1, 20)\n",
      "Original genome: [ True False  True False  True False  True False  True  True False  True\n",
      "  True  True  True  True  True  True  True False]\n",
      "Mutated genome:  [[ True False  True  True  True False  True False  True  True False  True\n",
      "   True  True  True  True  True  True  True  True]]\n",
      "Original parent (index 0):\n",
      "(100, 20)\n",
      "mutation_mask shape: (1, 20)\n",
      "\n",
      "Mutated parent (index 0):\n",
      "[[ True False  True False  True False  True False  True False  True  True\n",
      "   True  True  True  True  True  True  True False]]\n",
      "\n",
      "Total bits flipped: 94358 out of 200000 bits (47.18%)\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Setup Mutation ---\n",
    "print(\"--- BitFlip Mutation ---\")\n",
    "key, mutate_key = random.split(key)\n",
    "\n",
    "# Instantiate the \"factory\" with static config\n",
    "bitflip_op_factory = BitFlipMutation(mutation_rate=0.1)\n",
    "   \n",
    "# --- 2. Get the JIT-compiled function ---\n",
    "# This function mutates *one* genome\n",
    "mutate_one_fn = bitflip_op_factory.get_compiled_function()\n",
    "\n",
    "#mutate just one genome for demonstration\n",
    "sample_genome = parent_population[0]\n",
    "mutated_genome = mutate_one_fn(sample_genome, mutate_key)\n",
    "print(f\"Original genome: {sample_genome}\")\n",
    "print(f\"Mutated genome:  {mutated_genome}\")\n",
    "\n",
    "# --- 3. vmap it to create a population-wide mutator ---\n",
    "# We map over axis 0 of keys and axis 0 of genomes\n",
    "mutate_pop_fn = jit(vmap(mutate_one_fn, in_axes=(0, 0)))\n",
    "\n",
    "# --- 4. Run Mutation ---\n",
    "# We'll mutate the `parent_population` we just selected\n",
    "print(f\"Original parent (index 0):\\n{parent_population.shape}\")\n",
    "\n",
    "\n",
    "# Create a key for each individual\n",
    "pop_size = parent_population.shape[0]\n",
    "master_key = jar.PRNGKey(0)\n",
    "mutate_keys = jar.split(master_key, pop_size)   # shape (pop_size, 2)\n",
    "mutated_population = mutate_pop_fn(parent_population, mutate_keys)\n",
    "\n",
    "print(f\"\\nMutated parent (index 0):\\n{mutated_population[0]}\")\n",
    "\n",
    "# See the difference\n",
    "diff = (parent_population != mutated_population).astype(jnp.int32)\n",
    "print(f\"\\nTotal bits flipped: {jnp.sum(diff)} out of {diff.size} bits ({100 * jnp.sum(diff) / diff.size:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b68e7d",
   "metadata": {},
   "source": [
    "### 3. Selection Operators\n",
    "\n",
    "**Goal**: Select `N` individuals to be parents.\n",
    "\n",
    "**Pattern**:\n",
    "1. Instantiate a **Selection** class (e.g., `TournamentSelection`) with static parameters:\n",
    "    - `number_of_choices`\n",
    "    - `tournament_size`\n",
    "2. Call `get_compiled_function()` to obtain the pure JAX function.\n",
    "3. The pure function signature:\n",
    "    ```python\n",
    "    (key, fitness_values) -> selected_indices\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e9910a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tournament Selection ---\n",
      "Original fitnesses (top 10): [13 13 13 14 14 14 14 15 15 16]\n",
      "\n",
      "Selected indices (shape (100,)):\n",
      "[ 6 90 23 87 95 73 95 26 54 90 83  7 39 54 92 39  9 16 45 20 93 57 54 96\n",
      " 24 21 87 42 57  9 48 39  1 32  1  6 86 54 41 91  7 49  5 88 42 70 38 86\n",
      "  6 53  8  8  1 90 95 39  1  6 83 95 93  5 20 21  1 49  1 94 86  1 95 63\n",
      " 83 95 30 36 87 97 16 70 56 40 53 57  5 91 90 64  5 93 92 20 62 53  5 86\n",
      " 87 77 57 73]\n",
      "\n",
      "Fitnesses of selected (top 10): [14 14 14 14 15 15 15 15 15 16]\n",
      "Average fitness BEFORE selection: 10.179999351501465\n",
      "Average fitness AFTER selection: 12.389999389648438\n",
      "\n",
      "Shape of new parent population: (100, 20)\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Setup Selection ---\n",
    "print(\"--- Tournament Selection ---\")\n",
    "key, select_key = random.split(key)\n",
    "\n",
    "# We want to select POP_SIZE individuals to create the next generation\n",
    "# (allowing duplicates, as tournament selection does)\n",
    "tourn_op_factory = TournamentSelection(\n",
    "    number_of_choices=POP_SIZE,\n",
    "    tournament_size=4\n",
    ")\n",
    "\n",
    "# --- 2. Get the JIT-compiled function ---\n",
    "# This is a pure function we can use in our main loop\n",
    "select_fn = jit(tourn_op_factory.get_compiled_function())\n",
    "\n",
    "# --- 3. Run Selection ---\n",
    "# Pass in the key and the fitness values\n",
    "selected_indices = select_fn(select_key, fitness_values)\n",
    "\n",
    "print(f\"Original fitnesses (top 10): {jnp.sort(fitness_values)[-10:]}\")\n",
    "print(f\"\\nSelected indices (shape {selected_indices.shape}):\\n{selected_indices}\")\n",
    "\n",
    "# Prove that selection worked:\n",
    "selected_fitnesses = fitness_values[selected_indices]\n",
    "print(f\"\\nFitnesses of selected (top 10): {jnp.sort(selected_fitnesses)[-10:]}\")\n",
    "print(f\"Average fitness BEFORE selection: {jnp.mean(fitness_values)}\")\n",
    "print(f\"Average fitness AFTER selection: {jnp.mean(selected_fitnesses)}\")\n",
    "\n",
    "# --- 4. Get the Parent Population ---\n",
    "# In the main GA loop, we'd use these indices to get the new population\n",
    "parent_population = population_tensors[selected_indices]\n",
    "print(f\"\\nShape of new parent population: {parent_population.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e94d7a",
   "metadata": {},
   "source": [
    "### 4. Mutation Operators\n",
    "\n",
    "**Goal**: Apply random variation to individuals.\n",
    "\n",
    "**Pattern**:\n",
    "1. **Instantiate** a Mutation class (e.g., `BitFlipMutation`) with static parameters (`mutation_rate`).\n",
    "2. **Compile** the mutation function using `get_compiled_function()` to obtain a pure JAX function.\n",
    "3. **Function Signature**:\n",
    "    ```python\n",
    "    (key, genome_tensor) -> mutated_genome_tensor\n",
    "    ```\n",
    "4. **Vectorization**: Use `vmap` to apply the mutation function across an entire population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d59a8875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- BitFlip Mutation ---\n",
      "Original parent (index 0):\n",
      "[False  True False False  True  True  True False False False False  True\n",
      "  True  True  True False False  True  True  True]\n",
      "mutation_mask shape: (1, 20)\n",
      "\n",
      "Mutated parent (index 0):\n",
      "[[False  True False False  True  True  True False  True False False  True\n",
      "   True  True  True False False False  True  True]]\n",
      "\n",
      "Total bits flipped: 93474\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Setup Mutation ---\n",
    "print(\"--- BitFlip Mutation ---\")\n",
    "key, mutate_key = random.split(key)\n",
    "\n",
    "# Instantiate the \"factory\" with static config\n",
    "bitflip_op_factory = BitFlipMutation(mutation_rate=0.1)\n",
    "\n",
    "# --- 2. Get the JIT-compiled function ---\n",
    "# This function mutates *one* genome\n",
    "mutate_one_fn = jit(bitflip_op_factory.get_compiled_function())\n",
    "\n",
    "# --- 3. vmap it to create a population-wide mutator ---\n",
    "# We map over axis 0 of keys and axis 0 of genomes\n",
    "mutate_pop_fn = jit(vmap(mutate_one_fn, in_axes=(0, 0)))\n",
    "\n",
    "# --- 4. Run Mutation ---\n",
    "# We'll mutate the `parent_population` we just selected\n",
    "print(f\"Original parent (index 0):\\n{parent_population[0]}\")\n",
    "\n",
    "# Create a key for each individual\n",
    "mutate_keys = random.split(mutate_key, POP_SIZE)\n",
    "mutated_population = mutate_pop_fn( parent_population, mutate_keys)\n",
    "\n",
    "print(f\"\\nMutated parent (index 0):\\n{mutated_population[0]}\")\n",
    "\n",
    "# See the difference\n",
    "diff = (parent_population != mutated_population).astype(jnp.int32)\n",
    "print(f\"\\nTotal bits flipped: {jnp.sum(diff)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d58efc0",
   "metadata": {},
   "source": [
    "### Example 2: BallMutation (Real-Valued)\n",
    "\n",
    "The same pattern works seamlessly across different genome types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce643ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ball Mutation ---\n",
      "Original real genome (index 0):\n",
      "[-0.5403094   0.38333678 -0.4683802   0.53857994 -0.712852   -0.8242552\n",
      "  0.34233332 -0.5783129   0.43055868  0.99890995]\n",
      "\n",
      "Mutated real genome (index 0):\n",
      "[-0.5403094   0.29410166 -0.4683802   0.53857994 -0.6486067  -0.79814005\n",
      "  0.33577687 -0.5783129   0.43055868  1.0857137 ]\n",
      "\n",
      "Final corrected genome (index 0):\n",
      "[-0.5403094   0.29410166 -0.4683802   0.53857994 -0.6486067  -0.79814005\n",
      "  0.33577687 -0.5783129   0.43055868  1.        ]\n",
      "Min value in pop: -1.0, Max value in pop: 1.0\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Setup Real Population ---\n",
    "print(\"--- Ball Mutation ---\")\n",
    "key, init_key_real, mutate_key_real = random.split(key, 3)\n",
    "\n",
    "real_config = RealGenomeConfig(array_shape=(10,), min_val=-1.0, max_val=1.0)\n",
    "real_init_fn = jit(vmap(RealGenome.get_random_initialization_compilable_from_config(real_config)))\n",
    "real_keys = random.split(init_key_real, POP_SIZE)\n",
    "real_population = real_init_fn(real_keys)\n",
    "\n",
    "print(f\"Original real genome (index 0):\\n{real_population[0]}\")\n",
    "\n",
    "# --- 2. Setup Mutation ---\n",
    "ball_op_factory = BallMutation(mutation_rate=0.5, mutation_strength=0.1)\n",
    "mutate_one_real_fn = jit(ball_op_factory.get_compiled_function())\n",
    "\n",
    "# --- 3. vmap and Run ---\n",
    "mutate_pop_real_fn = jit(vmap(mutate_one_real_fn, in_axes=(0, 0)))\n",
    "real_mutate_keys = random.split(mutate_key_real, POP_SIZE)\n",
    "\n",
    "mutated_real_population = mutate_pop_real_fn(real_mutate_keys, real_population)\n",
    "\n",
    "print(f\"\\nMutated real genome (index 0):\\n{mutated_real_population[0]}\")\n",
    "\n",
    "# --- 4. (Demo) Don't forget Autocorrection! ---\n",
    "# The mutation *could* have pushed values out of bounds.\n",
    "# We get the JIT-able correction function from the genome config.\n",
    "autocorrect_fn = jit(RealGenome.get_autocorrection_compilable_from_config(real_config))\n",
    "autocorrect_pop_fn = jit(vmap(autocorrect_fn))\n",
    "\n",
    "# Apply correction (in a real GA, you'd do this after mutation)\n",
    "final_population = autocorrect_pop_fn(mutated_real_population)\n",
    "print(f\"\\nFinal corrected genome (index 0):\\n{final_population[0]}\")\n",
    "print(f\"Min value in pop: {jnp.min(final_population)}, Max value in pop: {jnp.max(final_population)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f67a5f7",
   "metadata": {},
   "source": [
    "## 5. Crossover Operators\n",
    "\n",
    "**Goal**: Create new offspring from pairs of parents.\n",
    "\n",
    "**Pattern**:\n",
    "1. **Instantiate** a Crossover class (e.g., `UniformCrossover`) with static parameters:\n",
    "    - `crossover_rate`\n",
    "    - `n_outputs`\n",
    "2. **Compile** the crossover function using `get_compiled_function()` to obtain the pure JAX function.\n",
    "3. **Function Signature**:\n",
    "    ```python\n",
    "    (key, parent1_tensor, parent2_tensor) -> offspring_batch\n",
    "    ```\n",
    "4. **Output**:\n",
    "    - The `offspring_batch` has shape `(n_outputs, ...genome_shape)`.\n",
    "5. **Vectorization**:\n",
    "    - Use `vmap` to apply the crossover function across the entire population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bb96f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Binary Uniform Crossover ---\n",
      "Parent 1 (index 0):\n",
      "[ True False  True  True False  True  True False  True  True  True False\n",
      "  True  True False  True False  True  True False]\n",
      "Parent 2 (index 0):\n",
      "[ True False  True  True False  True  True  True  True False False False\n",
      " False False  True False  True  True  True  True]\n",
      "\n",
      "Shape of offspring batches: (50, 2, 20)\n",
      "(num_pairs, n_outputs_per_pair, genome_length)\n",
      "\n",
      "Final new population shape: (100, 20)\n",
      "\n",
      "Offspring 0 (from pair 0):\n",
      "[ True False  True  True False  True  True False  True False False False\n",
      "  True False False  True False  True  True False]\n",
      "Offspring 1 (from pair 0):\n",
      "[ True False  True  True False  True  True  True  True  True  True False\n",
      " False  True  True False  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Setup Crossover ---\n",
    "print(\"--- Binary Uniform Crossover ---\")\n",
    "key, cross_key = random.split(key)\n",
    "\n",
    "# Instantiate the \"factory\"\n",
    "# We'll create 2 offspring for every 1 pair of parents\n",
    "cross_op_factory = BinaryUniform(crossover_rate=0.5, n_outputs=2)\n",
    "\n",
    "# --- 2. Get the JIT-compiled function ---\n",
    "# This function crosses *one pair* of parents\n",
    "cross_one_pair_fn = jit(cross_op_factory.get_compiled_function())\n",
    "\n",
    "# --- 3. Prepare Parent Pairs ---\n",
    "# We need two populations of parents. We'll shuffle our\n",
    "# parent_population to get two different-ordered lists.\n",
    "key, shuffle_key1, shuffle_key2 = random.split(key, 3)\n",
    "\n",
    "parents_1 = random.permutation(shuffle_key1, parent_population, axis=0)\n",
    "parents_2 = random.permutation(shuffle_key2, parent_population, axis=0)\n",
    "\n",
    "print(f\"Parent 1 (index 0):\\n{parents_1[0]}\")\n",
    "print(f\"Parent 2 (index 0):\\n{parents_2[0]}\")\n",
    "\n",
    "# --- 4. vmap the Crossover Function ---\n",
    "# We map over axis 0 of keys, axis 0 of parents_1, and axis 0 of parents_2\n",
    "cross_pop_fn = jit(vmap(cross_one_pair_fn, in_axes=(0, 0, 0)))\n",
    "\n",
    "# --- 5. Run Crossover ---\n",
    "# We only need POP_SIZE / n_outputs keys, since each key generates n_outputs offspring\n",
    "num_pairs = POP_SIZE // 2\n",
    "cross_keys = random.split(cross_key, num_pairs)\n",
    "\n",
    "# Run crossover on the first 50 pairs\n",
    "offspring_batches = cross_pop_fn(\n",
    "    cross_keys,\n",
    "    parents_1[:num_pairs],\n",
    "    parents_2[:num_pairs]\n",
    ")\n",
    "\n",
    "print(f\"\\nShape of offspring batches: {offspring_batches.shape}\")\n",
    "print(f\"(num_pairs, n_outputs_per_pair, genome_length)\")\n",
    "\n",
    "# --- 6. Flatten into the new population ---\n",
    "new_population = offspring_batches.reshape((POP_SIZE, GENOME_LENGTH))\n",
    "print(f\"\\nFinal new population shape: {new_population.shape}\")\n",
    "\n",
    "print(f\"\\nOffspring 0 (from pair 0):\\n{new_population[0]}\")\n",
    "print(f\"Offspring 1 (from pair 0):\\n{new_population[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a81bf0d",
   "metadata": {},
   "source": [
    "### Example 2: AverageCrossover (Real-Valued)\n",
    "\n",
    "The same `vmap`-based pattern applies seamlessly to real-valued genomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47cb9f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Real Average Crossover ---\n",
      "Real Parent 1 (index 0):\n",
      "[-0.53999996  0.38       -0.47        0.53999996 -0.71       -0.82\n",
      "  0.34       -0.58        0.42999998  1.        ]\n",
      "Real Parent 2 (index 0):\n",
      "[ 0.29999998  0.98999995  0.79999995  0.68        0.45        0.66999996\n",
      " -0.90999997  0.32999998 -0.48        0.42      ]\n",
      "\n",
      "Offspring 0 (should be avg of P1[0] and P2[0]):\n",
      "[-0.12  0.69  0.17  0.61 -0.13 -0.08 -0.28 -0.12 -0.03  0.71]\n",
      "Manual average:\n",
      "[-0.12  0.69  0.17  0.61 -0.13 -0.08 -0.28 -0.12 -0.03  0.71]\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Setup Real Crossover ---\n",
    "print(\"--- Real Average Crossover ---\")\n",
    "key, cross_key_real, shuffle_key_real = random.split(key, 3)\n",
    "\n",
    "# We'll use the 'real_population' from the mutation demo\n",
    "parents_real_1 = real_population\n",
    "parents_real_2 = random.permutation(shuffle_key_real, real_population, axis=0)\n",
    "\n",
    "print(f\"Real Parent 1 (index 0):\\n{parents_real_1[0].round(2)}\")\n",
    "print(f\"Real Parent 2 (index 0):\\n{parents_real_2[0].round(2)}\")\n",
    "\n",
    "# --- 2. Get JIT function (with blend_rate=0.5) ---\n",
    "avg_cross_factory = AverageCrossover(blend_rate=0.5, n_outputs=2)\n",
    "cross_one_avg_fn = jit(avg_cross_factory.get_compiled_function())\n",
    "\n",
    "# --- 3. vmap and Run ---\n",
    "cross_pop_avg_fn = jit(vmap(cross_one_avg_fn, in_axes=(0, 0, 0)))\n",
    "avg_cross_keys = random.split(cross_key_real, num_pairs) # Use 50 keys\n",
    "\n",
    "avg_offspring_batches = cross_pop_avg_fn(\n",
    "    avg_cross_keys,\n",
    "    parents_real_1[:num_pairs],\n",
    "    parents_real_2[:num_pairs]\n",
    ")\n",
    "\n",
    "# --- 4. Check results ---\n",
    "new_real_population = avg_offspring_batches.reshape((POP_SIZE, 10))\n",
    "print(f\"\\nOffspring 0 (should be avg of P1[0] and P2[0]):\\n{new_real_population[0].round(2)}\")\n",
    "\n",
    "# Verification\n",
    "manual_avg = (parents_real_1[0] + parents_real_2[0]) / 2.0\n",
    "print(f\"Manual average:\\n{manual_avg.round(2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GP_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
